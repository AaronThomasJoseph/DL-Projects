{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AaronThomasJoseph/DL-Projects/blob/main/RNN%20%26%20LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vYyvr-yeVeE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import os\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, SimpleRNN, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbQVzklUg2bc"
      },
      "outputs": [],
      "source": [
        "#Extracting Files\n",
        "#with zipfile.ZipFile(\"Group21_Assignment4.zip\",\"r\") as zip_ref:\n",
        "#    zip_ref.extractall()\n",
        "#zip_ref.close()\n",
        "\n",
        "#with zipfile.ZipFile(\"Group21_Assignment4/CV_Data.zip\",\"r\") as zip_ref:\n",
        "#    zip_ref.extractall()\n",
        "#zip_ref.close()\n",
        "\n",
        "with zipfile.ZipFile(\"Handwriting_Data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "zip_ref.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdWH4BwXJuPe"
      },
      "source": [
        "#**`Handwritten Character Dataset`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abnciZWYi9P2"
      },
      "outputs": [],
      "source": [
        "#Reading Text Data\n",
        "def load_text_data_from_folder(folder):\n",
        "    Data = []\n",
        "    for filename in os.listdir(folder):\n",
        "        data = np.loadtxt(os.path.join(folder,filename))\n",
        "        row = []\n",
        "        for x,y in zip(data[1::2],data[2::2]):\n",
        "          row.append([x,y])\n",
        "        row = np.array(row)\n",
        "        row[:,0] /= max(row[:,0])\n",
        "        row[:,1] /= max(row[:,1])\n",
        "        Data.append(row)\n",
        "    return Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgaU7XeZknfk",
        "outputId": "4e6731d3-ba3f-4b87-ef7f-08453b98c8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "train_a   = load_text_data_from_folder(\"Handwriting_Data/ai/train\")\n",
        "train_ai  = load_text_data_from_folder(\"Handwriting_Data/bA/train\")\n",
        "train_bA  = load_text_data_from_folder(\"Handwriting_Data/chA/train\")\n",
        "train_chA = load_text_data_from_folder(\"Handwriting_Data/lA/train\")\n",
        "train_lA  = load_text_data_from_folder(\"Handwriting_Data/tA/train\")\n",
        "\n",
        "x_train_HW = np.concatenate([train_a,train_ai,train_bA,train_chA,train_lA])\n",
        "y_train_HW = np.concatenate([0*np.ones(len(train_a)),1*np.ones(len(train_ai)),\n",
        "                          2*np.ones(len(train_bA)),3*np.ones(len(train_chA)),\n",
        "                          4*np.ones(len(train_lA))])\n",
        "\n",
        "test_a   = load_text_data_from_folder(\"Handwriting_Data/ai/dev\")\n",
        "test_ai  = load_text_data_from_folder(\"Handwriting_Data/bA/dev\")\n",
        "test_bA  = load_text_data_from_folder(\"Handwriting_Data/chA/dev\")\n",
        "test_chA = load_text_data_from_folder(\"Handwriting_Data/lA/dev\")\n",
        "test_lA  = load_text_data_from_folder(\"Handwriting_Data/tA/dev\")\n",
        "\n",
        "x_test_HW = np.concatenate([test_a,test_ai,test_bA,test_chA,test_lA])\n",
        "y_test_HW = np.concatenate([0*np.ones(len(test_a)),1*np.ones(len(test_ai)),\n",
        "                          2*np.ones(len(test_bA)),3*np.ones(len(test_chA)),\n",
        "                          4*np.ones(len(test_lA))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5DsJEdFDGaz"
      },
      "source": [
        "##**`Plot`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsLq8t0kDF_2"
      },
      "outputs": [],
      "source": [
        "def Plot(Data,nrow,ncol,index,title):\n",
        "  for img in Data:\n",
        "    plt.subplot(nrow,ncol,index)\n",
        "    plt.plot(img[:,0],img[:,1],marker=\".\",color='slateblue')\n",
        "    plt.xticks([]);plt.yticks([])\n",
        "\n",
        "    if index%5==1:\n",
        "      plt.ylabel(title,fontweight=\"bold\",fontsize=10,color='lime')\n",
        "      if index==11:\n",
        "        plt.text(x=0.15, y=0.30, s=\"Class:\",fontweight=\"bold\",fontsize=10,color='orange',rotation='vertical')\n",
        "    if index<=5:\n",
        "      plt.title(str(index),fontweight=\"bold\",fontsize=10,color='lime')\n",
        "      if index==3:\n",
        "        plt.text(x=0.685, y=1+1.25e-1, s=\"Image:\",fontweight=\"bold\",fontsize=10,color='orange')\n",
        "    index+=1\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.suptitle(\"HandWritten Character\",fontweight=\"bold\",y=1+1e-2,color='tomato')\n",
        "\n",
        "Plot(train_a[0:5],  5,5,1,\"a\")\n",
        "Plot(train_ai[0:5], 5,5,6,\"ai\")\n",
        "Plot(train_bA[0:5], 5,5,11,\"bA\")\n",
        "Plot(train_chA[0:5],5,5,16,\"chA\")\n",
        "Plot(train_lA[0:5], 5,5,21,\"lA\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaZl3wJu74I3"
      },
      "source": [
        "#**`Consonant Vowel (CV) Segment Dataset`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXRwwx4l8UDd"
      },
      "outputs": [],
      "source": [
        "#Reading MFCC Data\n",
        "def load_mfcc_data_from_folder(folder):\n",
        "    Data = []\n",
        "    for filename in os.listdir(folder):\n",
        "        data = np.loadtxt(os.path.join(folder,filename))\n",
        "        Data.append(data)\n",
        "    return Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMozycoY8vW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4398a698-d6dd-4cef-f8d1-22d2b18ab2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "train_pa   = load_mfcc_data_from_folder(\"CV_Data/pa/Train\")\n",
        "train_ba   = load_mfcc_data_from_folder(\"CV_Data/ba/Train\")\n",
        "train_hai  = load_mfcc_data_from_folder(\"CV_Data/hai/Train\")\n",
        "train_kaa  = load_mfcc_data_from_folder(\"CV_Data/kaa/Train\")\n",
        "train_sa   = load_mfcc_data_from_folder(\"CV_Data/sa/Train\")\n",
        "\n",
        "x_train_CV = np.concatenate([train_pa,train_ba,train_hai,train_kaa,train_sa])\n",
        "y_train_CV = np.concatenate([0*np.ones(len(train_pa)),1*np.ones(len(train_ba)),\n",
        "                          2*np.ones(len(train_hai)),3*np.ones(len(train_kaa)),\n",
        "                          4*np.ones(len(train_sa))])\n",
        "\n",
        "test_pa   = load_mfcc_data_from_folder(\"CV_Data/pa/Test\")\n",
        "test_ba   = load_mfcc_data_from_folder(\"CV_Data/ba/Test\")\n",
        "test_hai  = load_mfcc_data_from_folder(\"CV_Data/hai/Test\")\n",
        "test_kaa  = load_mfcc_data_from_folder(\"CV_Data/kaa/Test\")\n",
        "test_sa   = load_mfcc_data_from_folder(\"CV_Data/sa/Test\")\n",
        "\n",
        "x_test_CV = np.concatenate([test_pa,test_ba,test_hai,test_kaa,test_sa])\n",
        "y_test_CV = np.concatenate([0*np.ones(len(test_pa)),1*np.ones(len(test_ba)),\n",
        "                          2*np.ones(len(test_hai)),3*np.ones(len(test_kaa)),\n",
        "                          4*np.ones(len(test_sa))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynp6ugm5Pdxa"
      },
      "source": [
        "##**`Plot`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYDn7N6APfW9"
      },
      "outputs": [],
      "source": [
        "def Plot(Data,nrow,ncol,index,title):\n",
        "  Data = np.swapaxes(Data, 0, 1)\n",
        "  plt.subplot(nrow,ncol,index)\n",
        "  sns.heatmap(Data, cmap=cm.coolwarm,vmin=-40,vmax=20)\n",
        "  plt.yticks([])\n",
        "  if index==1:\n",
        "    plt.ylabel(\"MFCC\",fontweight=\"bold\",fontsize=10,color='orange')\n",
        "  plt.xlabel(\"Time\",fontweight=\"bold\",fontsize=10,color='orange')\n",
        "  plt.title(title,fontweight=\"bold\",fontsize=10,color='lime')\n",
        "\n",
        "plt.figure(figsize=(15,3))\n",
        "plt.suptitle(\"Consonant Vowel (CV)\",fontweight=\"bold\",y=1+1e-2,color='tomato')\n",
        "\n",
        "Plot(train_pa[0],1,5,1,\"pa\")\n",
        "Plot(train_ba[0],1,5,2,\"ba\")\n",
        "Plot(train_hai[0],1,5,3,\"hai\")\n",
        "Plot(train_kaa[0],1,5,4,\"kaa\")\n",
        "Plot(train_sa[0],1,5,5,\"sa\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzKgZSGOZm1k"
      },
      "source": [
        "#**`Common Code`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik-qL5E-XQ6m"
      },
      "outputs": [],
      "source": [
        "#Converting one hot encoded test label to label\n",
        "def ohetolabel(array):\n",
        "  output = list()\n",
        "  for i in range(len(array)):\n",
        "    output.append(np.argmax(array[i]))\n",
        "  return np.array(output)\n",
        "\n",
        "#Plot cf matrix\n",
        "def cf_matrix_plot(cf_matrix,title,title2):\n",
        "  #group_names = ['True Neg','False Pos','False Neg','True Pos','True Pos','True Pos','True Pos','True Pos','True Pos']\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                  cf_matrix.flatten()]\n",
        "\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "\n",
        "  labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
        "            zip(group_counts,group_percentages)]\n",
        "\n",
        "  labels = np.asarray(labels).reshape(5,5)\n",
        "\n",
        "  ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
        "\n",
        "  ax.set_title(title,fontweight=\"bold\",color='orange');\n",
        "  ax.set_xlabel('\\nPredicted Class',fontweight=\"bold\",fontsize=10,color='lime')\n",
        "  ax.set_ylabel('Actual Class',fontweight=\"bold\",fontsize=10,color='lime');\n",
        "\n",
        "  ## Ticket labels - List must be in alphabetical order\n",
        "  if title2[-1]=='r':\n",
        "    ax.xaxis.set_ticklabels(['a','ai','bA','chA','lA'])\n",
        "    ax.yaxis.set_ticklabels(['a','ai','bA','chA','lA'])\n",
        "  else:\n",
        "    ax.xaxis.set_ticklabels(['pa','ba','hai','kaa','sa'])\n",
        "    ax.yaxis.set_ticklabels(['pa','ba','hai','kaa','sa'])\n",
        "\n",
        "def Display(history,y_train,y_train_pred,y_test,y_test_pred,title):\n",
        "  print(\"No of Epochs =\",len(history.history[\"loss\"]))\n",
        "  plt.figure(figsize=(8,4))\n",
        "  plt.suptitle(title,fontweight=\"bold\",y=1+1e-2,color='tomato')\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(history.history['accuracy'],marker='.')\n",
        "  plt.title('Model accuracy',fontweight=\"bold\",fontsize=10,color='orange')\n",
        "  plt.ylabel('Accuracy',fontweight=\"bold\",fontsize=10,color='lime')\n",
        "  plt.xlabel('Epoch',fontweight=\"bold\",fontsize=10,color='lime')\n",
        "  plt.legend(['Train'], loc='upper left')\n",
        "  plt.grid()\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(history.history['loss'],marker='.')\n",
        "  plt.title('Model loss',fontweight=\"bold\",fontsize=10,color='orange')\n",
        "  plt.ylabel('Loss',fontweight=\"bold\",fontsize=10,color='lime')\n",
        "  plt.xlabel('Epoch',fontweight=\"bold\",fontsize=10,color='lime')\n",
        "  plt.legend(['Train'], loc='upper left')\n",
        "  plt.grid()\n",
        "  plt.tight_layout();plt.show()\n",
        "\n",
        "  print(\"Training Accuracy =\\t\",history.history['accuracy'][-1])\n",
        "  print(\"Test Accuracy =\\t\",history.history['val_accuracy'][-1])\n",
        "\n",
        "  #Generate the confusion matrix\n",
        "  plt.figure(figsize=(8,4))\n",
        "  plt.suptitle(title,fontweight=\"bold\",y=1+1e-2,color='tomato')\n",
        "  plt.subplot(1,2,1)\n",
        "  cf_matrix = confusion_matrix(y_train, y_train_pred)\n",
        "  cf_matrix_plot(cf_matrix,\"Training Data\",title)\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  cf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "  cf_matrix_plot(cf_matrix,\"Test Data\",title)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"\\tTraining Data\\t\\t\\t\\tTest Data\")\n",
        "  print(\"Accuracy:\",end=\" \")\n",
        "  print(np.around(accuracy_score(y_train , y_train_pred),4),end=\"\\t\"*4)\n",
        "  print(np.around(accuracy_score(y_test , y_test_pred),4))\n",
        "\n",
        "  print(\"Precision:\",end=\"\")\n",
        "  print(np.around(precision_score(y_train , y_train_pred,average=\"macro\"),4),end=\"\\t\"*4)\n",
        "  print(np.around(precision_score(y_test , y_test_pred,average=\"macro\"),4))\n",
        "\n",
        "  print(\"Recall:\",end=\"   \")\n",
        "  print(np.around(recall_score(y_train , y_train_pred,average=\"macro\"),4),end=\"\\t\"*4)\n",
        "  print(np.around(recall_score(y_test , y_test_pred,average=\"macro\"),4))\n",
        "\n",
        "  print(\"F1-Score:\",end=\" \")\n",
        "  print(np.around(f1_score(y_train , y_train_pred,average=\"macro\"),4),end=\"\\t\"*4)\n",
        "  print(np.around(f1_score(y_test , y_test_pred,average=\"macro\"),4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuSiAynRKI03"
      },
      "source": [
        "#**`RNN`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BXBNnYsKGpT"
      },
      "outputs": [],
      "source": [
        "def rnn(x_train,x_test,y_train,y_test,h1,h2,input_shape,title):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(SimpleRNN(h1, input_shape=input_shape,activation='tanh',return_sequences=True))\n",
        "  model.add(SimpleRNN(h2,activation='tanh'))\n",
        "  model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  ohe = OneHotEncoder()\n",
        "  y_train = ohe.fit_transform(y_train.reshape(-1,1)).toarray()\n",
        "  y_test  = ohe.fit_transform(y_test.reshape(-1,1)).toarray()\n",
        "\n",
        "\n",
        "  def train_generator():\n",
        "    i = 0\n",
        "    while True:\n",
        "      x = x_train[i].reshape(1,-1,2)\n",
        "      y = y_train[i].reshape(1,5,1)\n",
        "      yield x,y\n",
        "      i+=1\n",
        "      i%=len(x_train)\n",
        "\n",
        "\n",
        "  def val_generator():\n",
        "    i = 0\n",
        "    while True:\n",
        "        x = x_test[i].reshape(1,-1,input_shape[-1])\n",
        "        y = y_test[i].reshape(1,5,1)\n",
        "        yield x, y\n",
        "        i+=1\n",
        "        i%=len(x_test)\n",
        "\n",
        "  error_th = 1e-4\n",
        "  keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "  es = EarlyStopping(monitor='loss',mode='min',min_delta = error_th,verbose=0,patience=5)\n",
        "  history = model.fit(train_generator(),steps_per_epoch=len(x_train),epochs=10,verbose=2,callbacks=[es],\n",
        "                       validation_data = val_generator(),validation_steps=len(x_test))\n",
        "  print(\"Training Accuracy =\\t\",history.history['accuracy'][-1])\n",
        "  # this is for prediction purpose\n",
        "  y_train_pred = []\n",
        "  y_test_pred  = []\n",
        "  for i in range(len(x_train)):\n",
        "    y_train_pred.append(model.predict(x_train[i].reshape(1,-1,input_shape[-1])))\n",
        "  for i in range(len(x_test)):\n",
        "    y_test_pred.append(model.predict(x_test[i].reshape(1,-1,input_shape[-1])))\n",
        "  y_train_pred = np.array(y_train_pred)\n",
        "  y_test_pred  = np.array(y_test_pred)\n",
        "  #Converting one hot encoded test label to label\n",
        "  def ohetolabel(array):\n",
        "    output = list()\n",
        "    for i in range(len(array)):\n",
        "      output.append(np.argmax(array[i]))\n",
        "    return np.array(output)\n",
        "  y_train      = ohetolabel(y_train)\n",
        "  y_test       = ohetolabel(y_test)\n",
        "  y_train_pred = ohetolabel(y_train_pred)\n",
        "  y_test_pred  = ohetolabel(y_test_pred)\n",
        "\n",
        "  print(\"test accuracy :\")\n",
        "\n",
        "  print(np.around(accuracy_score(y_test , y_test_pred),4))\n",
        "  print(confusion_matrix(y_test , y_test_pred))\n",
        "  Display(history,y_train,y_train_pred,y_test,y_test_pred,title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNqDuYIoO5CT"
      },
      "source": [
        "##**`Handwritten Character`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3cKtMHWOD4j"
      },
      "outputs": [],
      "source": [
        "h1 = 8\n",
        "h2 = 8\n",
        "input_shape = (None,2)\n",
        "title='RNN: Handwritten Character'\n",
        "rnn(x_train_HW,x_test_HW,y_train_HW,y_test_HW,h1,h2,input_shape,title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smtV0jzhPQAJ"
      },
      "source": [
        "##**`Constant Vowel(CV) Segment`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ozsmnj6PLBE"
      },
      "outputs": [],
      "source": [
        "h1 = 16\n",
        "h2 = 8\n",
        "input_shape = (None,39)\n",
        "title='RNN: Constant Vowel(CV) Segment'\n",
        "rnn(x_train_CV,x_test_CV,y_train_CV,y_test_CV,h1,h2,input_shape,title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz2F-dQZPM2U"
      },
      "source": [
        "#**`LSTM`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX1drG-zOV83"
      },
      "outputs": [],
      "source": [
        "def lstm(x_train,x_test,y_train,y_test,h1,h2,input_shape,title):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(h1, input_shape=input_shape,activation='tanh',return_sequences=True))\n",
        "  model.add(LSTM(h2, activation='tanh'))\n",
        "  model.add(Dense(5,activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  ohe = OneHotEncoder()\n",
        "  y_train = ohe.fit_transform(y_train.reshape(-1,1)).toarray()\n",
        "  y_test  = ohe.fit_transform(y_test.reshape(-1,1)).toarray()\n",
        "\n",
        "  index = list(range(len(x_train)))\n",
        "  def train_generator():\n",
        "    ind=0\n",
        "    while True:\n",
        "        i = index[ind]\n",
        "        x = x_train[i].reshape(1,-1,input_shape[-1])\n",
        "        y = y_train[i].reshape(1,5,1)\n",
        "        yield x, y\n",
        "        ind+=1\n",
        "        if ind==len(x_train):\n",
        "          np.random.shuffle(index)\n",
        "        ind%=len(x_train)\n",
        "\n",
        "  def val_generator():\n",
        "    i = 0\n",
        "    while True:\n",
        "        x = x_test[i].reshape(1,-1,input_shape[-1])\n",
        "        y = y_test[i].reshape(1,5,1)\n",
        "        yield x, y\n",
        "        i+=1\n",
        "        i%=len(x_test)\n",
        "\n",
        "  error_th = 1e-4\n",
        "  keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "  es = EarlyStopping(monitor='loss',min_delta = error_th,verbose=0,patience=5)\n",
        "  history = model.fit(train_generator(),steps_per_epoch=len(x_train),epochs=1000,verbose=2,callbacks=[es],\n",
        "                       validation_data = val_generator(),validation_steps=len(x_test))\n",
        "\n",
        "  # this is for prediction purpose\n",
        "  y_train_pred = []\n",
        "  y_test_pred  = []\n",
        "  for i in range(len(x_train)):\n",
        "    y_train_pred.append(model.predict(x_train[i].reshape(1,-1,input_shape[-1])))\n",
        "  for i in range(len(x_test)):\n",
        "    y_test_pred.append(model.predict(x_test[i].reshape(1,-1,input_shape[-1])))\n",
        "  y_train_pred = np.array(y_train_pred)\n",
        "  y_test_pred  = np.array(y_test_pred)\n",
        "\n",
        "  y_train      = ohetolabel(y_train)\n",
        "  y_test       = ohetolabel(y_test)\n",
        "  y_train_pred = ohetolabel(y_train_pred)\n",
        "  y_test_pred  = ohetolabel(y_test_pred)\n",
        "\n",
        "  Display(history,y_train,y_train_pred,y_test,y_test_pred,title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2duAACJQ4LX"
      },
      "source": [
        "##**`Handwritten Character`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZyYoWKiOc0S"
      },
      "outputs": [],
      "source": [
        "h1 = 4\n",
        "h2 = 4\n",
        "input_shape = (None,2)\n",
        "title='LSTM: Handwritten Character'\n",
        "lstm(x_train_HW,x_test_HW,y_train_HW,y_test_HW,h1,h2,input_shape,title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLVZN3SnQ-DR"
      },
      "source": [
        "##**`Constant Vowel(CV) Segment`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsTgL_jnRDvz"
      },
      "outputs": [],
      "source": [
        "h1 = 8\n",
        "h2 = 8\n",
        "input_shape = (None,39)\n",
        "title='LSTM: Constant Vowel(CV) Segment'\n",
        "lstm(x_train_CV,x_test_CV,y_train_CV,y_test_CV,h1,h2,input_shape,title)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}